,[31],"Minesh Mathew, Viraj Bagal, Rubèn Tito, Dimosthenis",
0,[32],"Karatzas, Ernest Valveny, and CV Jawahar. Infographicvqa. In Proceedings of the IEEE/CVF Winter Conference on Ap- plications of Computer Vision, pages 1697-1706, 2022. 6, 12 Minesh Mathew, Dimosthenis Karatzas, and CV Jawahar. Docvqa: A dataset for vqa on document images. In Proceed- ings of the IEEE/CVF winter conference on applications of",[45] [46]
1,[33] [34] [35] [36],"computer vision, pages 2200-2209, 2021. 2, 6, 12 Seunghyun Park, Seung Shin, Bado Lee, Junyeop Lee, Jaehe- ung Surh, Minjoon Seo, and Hwalsuk Lee. Cord: a consol- idated receipt dataset for post-ocr parsing. In Workshop on Document Intelligence at NeurIPS 2019, 2019. 2,6 Panupong Pasupat and Percy Liang. Compositional se- mantic parsing on semi-structured tables. arXiv preprint arXiv:1508.00305, 2015. 6, 12 Rafał Powalski, Łukasz Borchmann, Dawid Jurkiewicz, Tomasz Dwojak, Michał Pietruszka, and Gabriela Pałka. Go- ing full-tilt boogie on document understanding with text- image-layout transformer. In International Conference on Document Analysis and Recognition, pages 732-747. Springer, 2021. 1, 3, 7, 9, 15 Subhojeet Pramanik, Shashank Mujumdar, and Hima Patel. Towards a multi-modal, multi-task learning based pre-training framework for document representation learning. arXiv 2009.14457, 2020. 1",[47] [48] [49]
2,[37],"preprint arXiv: Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In",[50]
3,[38],"International Conference on Machine Learning, pages 8748-8763. PMLR, 2021. 4,9 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a",[51]
4,[39],"unified text-to-text transformer. JMLR, 2020. 6, 7, 15 Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for machine comprehen-",
5,[40],"sion of text. In EMNLP, 2016. 15 Tomasz Stanisławek, Filip Graliński, Anna Wróblewska, Dawid Lipiński, Agnieszka Kaliska, Paulina Rosalska, Bar- tosz Topolski, and Przemysław Biecek. Kleister: key infor- mation extraction datasets involving long documents with complex layouts. In International Conference on Document Analysis and Recognition, pages 564–579. Springer, 2021. 6,",[52] [53]
6,[41] [42],"12 Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai. Vl-bert: Pre-training of generic visual- linguistic representations. In International Conference on Learning Representations, 2019. 9 S Svetlichnaya. Deepform: Understand structured documents at scale, 2020. 6, 12",[54]
7,[43],Hao Tan and Mohit Bansal. Lxmert: Learning cross-modality,
8,,"encoder representations from transformers. In EMNLP, 2019. 1",
9,[44],"Ryota Tanaka, Kyosuke Nishida, and Sen Yoshida. Visualmrc: Machine reading comprehension on document images. In",[55]
